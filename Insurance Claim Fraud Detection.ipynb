{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c566f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96452aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"https://raw.githubusercontent.com/dsrscientist/Data-Science-ML-Capstone-Projects/master/Automobile_insurance_fraud.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efcfd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78914cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop('_c39',axis=1,inplace=True)\n",
    "df.drop(['policy_number','incident_location'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31febbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = [y for y in df.columns if df[y].dtypes != 'O']\n",
    "df[num_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73774ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa744e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['collision_type'].value_counts())\n",
    "print(df['property_damage'].value_counts())\n",
    "print(df['police_report_available'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b445e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the character ? with mean of the feature\n",
    "\n",
    "df['collision_type']=df['collision_type'].replace(\n",
    "    to_replace='?', \n",
    "    value='Rear Collision', \n",
    "    inplace=False, \n",
    "    limit=None, \n",
    "    regex=False, method='pad')\n",
    "df['property_damage']=df['property_damage'].replace(\n",
    "    to_replace='?', \n",
    "    value='No', \n",
    "    inplace=False, \n",
    "    limit=None, \n",
    "    regex=False, method='pad')\n",
    "df['police_report_available']=df['police_report_available'].replace(\n",
    "    to_replace='?', \n",
    "    value='No', \n",
    "    inplace=False, \n",
    "    limit=None, \n",
    "    regex=False, method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a963e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "df['policy_year'] = pd.to_datetime(df.policy_bind_date,format='%d-%m-%Y')\n",
    "df['incident_year'] = pd.to_datetime(df.incident_date, format='%d-%m-%Y')\n",
    "df['policy_year'] = df['policy_year'].dt.strftime('%Y')\n",
    "df['incident_year'] = df['incident_year'].dt.strftime('%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['policy_bind_date','incident_date'],axis=1,inplace=True)\n",
    "\n",
    "# grouping categorical variables \n",
    "cat_vars = [x for x in df.columns if df[x].dtypes == 'O']\n",
    "df[cat_vars]\n",
    "cat_vars.remove('policy_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5aa923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for any skewness in the dataset\n",
    "for i in df.columns:\n",
    "    sns.histplot(df[i],bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for outliers\n",
    "\n",
    "def boxplots_custom(dataset, columns_list, rows, cols, subtitle):\n",
    "    fig, axs = plt.subplots(rows, cols, sharey=True, figsize=(16,12))\n",
    "#     fig.subtitle(subtitle,y=0.63, size=14)\n",
    "    axs = axs.flatten()\n",
    "    for i, data in enumerate(columns_list):\n",
    "        if i % 3 == 0:\n",
    "            axs[i].set_ylabel('The number of entries')\n",
    "        sns.boxplot(data=dataset[data], orient='h', ax=axs[i])\n",
    "        axs[i].set_title(data)\n",
    "        \n",
    "boxplots_custom(dataset=df, columns_list=num_vars, rows=6, cols=3, subtitle='Boxplots before deleting outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting countplot\n",
    "for i in num_vars:\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.countplot(df[i],hue=df['fraud_reported'],palette='GnBu')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4231deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x='age',y='months_as_customer',data=df,jitter=True,hue='fraud_reported',palette='GnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdace18",
   "metadata": {},
   "source": [
    "There are more number of Genuine cases who claim insurance and the months as a customer will gradually increases with the age of the insured suggesting that the insured is a Genuine customer & will not make any fraud claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b603b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x='months_as_customer',y='injury_claim',data=df,jitter=True,hue='fraud_reported',palette='GnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6819baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x='months_as_customer',y='vehicle_claim',data=df,jitter=True,hue='fraud_reported',palette='GnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e9a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x='total_claim_amount',y='injury_claim',data=df,jitter=True,hue='fraud_reported',palette='GnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed00b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x='total_claim_amount',y='property_claim',data=df,jitter=True,hue='fraud_reported',palette='GnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x='vehicle_claim',y='total_claim_amount',data=df,jitter=True,hue='fraud_reported',palette='GnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3768935",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx, ax = plt.subplots(nrows=1, ncols=1, figsize=(25,19))\n",
    "ax.set_title('Correlation Matrix', fontsize=16)\n",
    "\n",
    "sns.heatmap(df.corr(), vmin=-1, vmax=1, cmap='GnBu', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5489613",
   "metadata": {},
   "source": [
    "### label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelizing categorical variables\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb=LabelEncoder()\n",
    "df[cat_vars]=df[cat_vars].apply(lb.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting outliers\n",
    "Q1 = df[num_vars].quantile(0.25)\n",
    "Q3 = df[num_vars].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print('Here we will get IQR for each column\\n',IQR)\n",
    "\n",
    "df= df[~((df[num_vars] < (Q1 - 1.5 * IQR)) |(df[num_vars] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4efc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['fraud_reported','incident_year'],axis=1)\n",
    "y=df['fraud_reported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9a234",
   "metadata": {},
   "source": [
    "### Re-shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "# splitting the dataset in to train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.33, random_state=42)\n",
    "#combine them back for resampling\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "# separate minority and majority classes\n",
    "negative = train_data[train_data.fraud_reported==0]\n",
    "positive = train_data[train_data.fraud_reported==1]\n",
    "# upsample minority\n",
    "pos_upsampled = resample(negative,\n",
    " replace=True, # sample with replacement\n",
    " n_samples=len(positive), # match number in majority class\n",
    " random_state=27) # reproducible results\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([positive, pos_upsampled])\n",
    "# check new class counts\n",
    "upsampled.fraud_reported.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c587350",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=upsampled.drop('fraud_reported',axis=1)\n",
    "y=upsampled['fraud_reported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff3e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing skewness\n",
    "x.skew()\n",
    "from sklearn.preprocessing import power_transform\n",
    "x[num_vars]=power_transform(x[num_vars],method='yeo-johnson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f873607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import al the necessary libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56949b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test set\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd9814c",
   "metadata": {},
   "source": [
    "### Scaling the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912870c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "standardized_x=scaler.fit_transform(x_train)\n",
    "standardized_xtest=scaler.fit_transform(x_test)\n",
    "df_standardized = pd.DataFrame(data=standardized_x)\n",
    "df_standardized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb72668",
   "metadata": {},
   "outputs": [],
   "source": [
    "models= [('lr',LogisticRegression()),('rfc',RandomForestClassifier()),('etc',ExtraTreesClassifier()),('bgc',BaggingClassifier()),\n",
    "        ('gbc',GradientBoostingClassifier()),('dtc',DecisionTreeClassifier()),('knn',KNeighborsClassifier()),\n",
    "        ('bnb',BernoulliNB()),('svc',SVC())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1c1d0",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find crossValidation score of different models\n",
    "\n",
    "def basic_model_selection(x,y,cross_folds,model):\n",
    "    scores=[]\n",
    "    names = []\n",
    "    for i,j in model:\n",
    "        cv_scores = cross_val_score(j, x, y, cv=cross_folds,n_jobs=-1)\n",
    "        scores.append(cv_scores)\n",
    "        names.append(i)\n",
    "    for k in range(len(scores)):\n",
    "        print(names[k],scores[k].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16066b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model_selection(standardized_x,y_train,10,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {'n_estimators':range(20,81,10)}\n",
    "gbc_search= GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='accuracy',n_jobs=4,cv=5)\n",
    "gbc_search.fit(standardized_x,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_search.best_params_, gbc_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8368d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc= GradientBoostingClassifier(max_depth=8,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=50,\n",
    "                                min_samples_split=500,\n",
    "                                random_state=10,\n",
    "                                subsample=0.8,n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6023ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.fit(standardized_x,y_train)\n",
    "pred_gbc=gbc.predict(standardized_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d63797",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(pred_gbc,y_test))\n",
    "print(classification_report(pred_gbc,y_test))\n",
    "confusion_matrix(y_test,pred_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78934c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score,roc_auc_score,roc_curve\n",
    "sm = SMOTE(random_state=42,n_jobs=-1)\n",
    "X_train, Y_train = sm.fit_resample(standardized_x,y_train)\n",
    "\n",
    "smote = GradientBoostingClassifier(max_depth=8,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=50,\n",
    "                                min_samples_split=500,\n",
    "                                random_state=10,\n",
    "                                subsample=0.8,n_estimators=20).fit(X_train,Y_train)\n",
    "\n",
    "smote_pred = smote.predict(standardized_xtest)\n",
    "\n",
    "# Checking accuracy\n",
    "accuracy_score(y_test, smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9baa0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(smote_pred,y_test))\n",
    "print(classification_report(smote_pred,y_test))\n",
    "confusion_matrix(y_test,smote_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f093eb",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning for Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca624e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'base_estimator__max_depth' : [1, 2, 3, 4, 5],\n",
    "    'max_samples' : [0.05, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(BaggingClassifier(RandomForestClassifier(),\n",
    "                                     n_estimators = 100, max_features = 0.5),\n",
    "                   param_grid, scoring = 'accuracy')\n",
    "clf.fit(standardized_x, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_bgc = BaggingClassifier(n_estimators = 100, max_features = 0.5).fit(standardized_x,y_train)\n",
    "\n",
    "smote_pred_bgc = smote_bgc.predict(standardized_xtest)\n",
    "\n",
    "# Checking accuracy\n",
    "accuracy_score(y_test, smote_pred_bgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7676edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(smote_pred_bgc,y_test))\n",
    "print(classification_report(smote_pred_bgc,y_test))\n",
    "confusion_matrix(y_test,smote_pred_bgc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2022650",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df={\"Predicted Loan_Status\":smote_pred_bgc,\"Original Loan_Status\":y_test}\n",
    "predicted_df=pd.DataFrame(predicted_df)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90163002",
   "metadata": {},
   "source": [
    "### creating pickel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eddbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'Insurance.pkl'\n",
    "pickle.dump(smote_bgc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('Insurance.pkl', 'rb'))\n",
    "result = loaded_model.score(standardized_xtest, y_test)\n",
    "print(result*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579bd558",
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion=pd.DataFrame([loaded_model.predict(standardized_xtest)[:],y_test[:]],index=[\"Predicted\",\"Original\"])\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e0fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
